<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>TensorFlow.js Text Classifier</title>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0/dist/tf.min.js"></script>

  <style>
    body {
      font-family: Arial, sans-serif;
      max-width: 800px;
      margin: 40px auto;
    }
    textarea {
      width: 100%;
      height: 80px;
      font-size: 16px;
    }
    button {
      padding: 10px 20px;
      margin-top: 10px;
      font-size: 16px;
      cursor: pointer;
    }
    pre {
      background: #f4f4f4;
      padding: 10px;
      overflow-x: auto;
    }
    .result {
      font-size: 18px;
      margin-top: 15px;
    }
  </style>
</head>
<body>

<h1>TensorFlow.js Text Model Demo</h1>

<p>Enter an English sentence and run the model.</p>

<textarea id="inputText" placeholder="Type an English sentence here..."></textarea>
<br>
<button onclick="runModel()">Predict</button>

<div class="result" id="prediction"></div>

<h3>Tokens (word → index)</h3>
<pre id="tokens"></pre>

<script>
  let model;

  const MAX_LEN = 30;
  const VOCAB_SIZE = 8000;

  // Simple deterministic tokenizer (hash-based)
  function wordToIndex(word) {
    let hash = 0;
    for (let i = 0; i < word.length; i++) {
      hash = ((hash << 5) - hash) + word.charCodeAt(i);
      hash |= 0;
    }
    return Math.abs(hash) % VOCAB_SIZE;
  }

  function tokenize(text) {
    const words = text
      .toLowerCase()
      .replace(/[^a-z\s]/g, "")
      .split(/\s+/)
      .filter(w => w.length > 0);

    const tokens = words.map(w => wordToIndex(w));

    // Pad / truncate to length 30
    while (tokens.length < MAX_LEN) tokens.push(0);
    return tokens.slice(0, MAX_LEN);
  }

  async function loadModel() {
    model = await tf.loadLayersModel("model.json");
    console.log("Model loaded");
  }

  async function runModel() {
    if (!model) {
      alert("Model not loaded yet");
      return;
    }

    const text = document.getElementById("inputText").value;
    if (!text.trim()) return;

    const tokens = tokenize(text);

    const inputTensor = tf.tensor2d([tokens], [1, MAX_LEN], "int32");
    const prediction = model.predict(inputTensor);
    const value = (await prediction.data())[0];

    document.getElementById("prediction").innerHTML =
      `<strong>Prediction probability:</strong> ${value.toFixed(4)}<br>
       <strong>Class:</strong> ${value >= 0.5 ? "Positive" : "Negative"}`;

    const words = text
      .toLowerCase()
      .replace(/[^a-z\s]/g, "")
      .split(/\s+/)
      .filter(w => w.length > 0);

    const tokenMap = words.map(w => `${w} → ${wordToIndex(w)}`).join("\n");
    document.getElementById("tokens").textContent = tokenMap;

    tf.dispose([inputTensor, prediction]);
  }

  loadModel();
</script>

</body>
</html>
